# ğŸ”¬ MelaNoMore

**AI-Powered Skin Lesion Screening for Clinical Decision Support**

---

## Overview

**MelaNoMore** is a computer vision-based decision support tool designed to assist dermatologists in the early detection and classification of skin lesions. By combining edge AI on the **Arduino Nicla Vision** with a powerful server-side deep learning model, MelaNoMore provides a two-tier screening system that balances speed, accuracy, and accessibility.

### Key Features

- âš¡ **Fast on-device screening** - Binary classification (suspicious vs. non-suspicious) directly on the Nicla Vision
- ğŸ§  **Advanced server-side analysis** - Multi-class classification across 7 lesion types using Vision Transformer
- ğŸ“¡ **Seamless WiFi integration** - Automatic image upload for suspicious cases
- ğŸ¯ **Distance guidance** - Time-of-Flight sensor ensures correct positioning
- ğŸ’¡ **Intuitive LED feedback** - Color-coded status for real-time user guidance
- ğŸŒ **Web dashboard** - Accessible interface for reviewing detailed predictions

---

## ğŸ‘¥ Team

- **[Arslan](https://www.linkedin.com/in/arslan-ali-1804bbb1/)**
- **[Vittorio](https://www.linkedin.com/in/vittorio-sironi/)**
- **[Alessandro](https://www.linkedin.com/in/alessandro-sola03/)**

---

## Use Case

MelaNoMore serves as a **"second set of eyes"** for dermatologists during clinical examinations:

1. **Pre-screening** happens instantly on the handheld device, even offline
2. **Suspicious cases** are automatically escalated to a more powerful model running on a server
3. **Detailed classification** helps dermatologists make informed decisions about diagnosis and treatment

This workflow helps:
- â±ï¸ Save time during patient consultations
- ğŸ” Reduce diagnostic errors
- ğŸ©º Improve early detection of dangerous skin cancers like melanoma

---

## ğŸ—ï¸ System Architecture

MelaNoMore employs a **two-tier classification system**:

### Tier 1: Edge Device (Arduino Nicla Vision)
- **Model**: `fai-cls-n-coco` (Focoos AI)
- **Task**: Binary classification (suspicious vs. non-suspicious)
- **Input**: 96x96 RGB images
- **Inference**: Real-time, on-device
- **Output**: Classification + LED feedback

### Tier 2: Server (PC/Cloud)
- **Model**: Vision Transformer Large (ViT-L/16)
- **Task**: Multi-class classification across 7 lesion types
- **Parameters**: ~305M
- **Inference**: Triggered only for suspicious cases
- **Output**: Detailed classification with confidence scores

### Communication Flow

```
[Nicla Vision] -> Capture Image -> On-Device Inference
       |
  Suspicious?
       |
    [YES] -> WiFi Upload -> [Flask Server] -> ViT-L/16 Inference
       |                          |
    [NO]                   Web Dashboard
       |
   Green LED
```

---

## ğŸ§¬ Dataset

**HAM10000** (Human Against Machine with 10,000 training images)
Source: [ISIC Archive - Collection 212](https://api.isic-archive.com/collections/212/)

### Lesion Categories (7 classes)
1. Actinic Keratoses
2. Basal Cell Carcinoma
3. Benign Keratosis-like lesions
4. Dermatofibroma
5. Melanocytic Nevi
6. Melanoma
7. Vascular lesions

---

## ğŸ¤– Model Details

### Edge Model (Nicla Vision)
- **Architecture**: `fai-cls-n-coco` (Focoos AI)
- **Pretraining**: COCO dataset
- **Fine-tuning**: Binary classification on HAM10000 (suspicious vs. non-suspicious)
- **Input Size**: 96x96
- **Export Format**: ONNX with quantization
- **Deployment**: Flashed via Zant

### Server Model (PC)
- **Architecture**: Vision Transformer Large (ViT-L/16)
- **Parameters**: ~305M
- **Pretraining**: ImageNet-21k
- **Fine-tuning**: HAM10000 with Focal Loss (to handle class imbalance)
- **Framework**: PyTorch

### Performance Metrics

<table>
<tr>
<td width="50%">

**Edge Model (Nicla Vision)**
*Binary Classification*

| Metric | Score |
|--------|-------|
| **Accuracy** | 76% |
| **Precision** | 67.99% |
| **Recall** | 94.01% |
| **F1-Score** | 76.44% |

</td>
<td width="50%">

**Server Model (ViT-L/16)**
*Multi-Class Classification*

| Metric | Score |
|--------|-------|
| **Accuracy** | 84.60% |
| **F1 (Macro)** | 72.80% |
| **F1 (Weighted)** | 83.40% |

</td>
</tr>
</table>


---

## ğŸ”§ Hardware Components

### Required Hardware
- **Arduino Nicla Vision** - Edge AI processing and image capture
- **PC/Server** - Flask web server + Vision Transformer inference

### Device Integration
The Nicla Vision is integrated into a handheld, dermatoscope-like form factor for ease of use in clinical settings.

---

## ğŸ’» Software Stack

### On-Device (Arduino Nicla Vision)
- Arduino IDE
- Focoos AI platform (model training & export)
- ONNX runtime
- Zant (firmware flashing)

### Server-Side (PC)
- Python 3.8+
- Flask (web server)
- PyTorch
- torchvision
- scikit-learn
- NumPy, Pandas

---

## ğŸš€ Getting Started

### 1. Hardware Setup
1. Assemble the MelaNoMore handheld device with Nicla Vision
2. Ensure ToF sensor and camera are properly connected
3. Verify LED indicators are functional

### 2. Deploy Edge Model
```bash
# Flash the ONNX model to Nicla Vision using Zant
zant flash --model model.onnx --device nicla-vision
```

### 3. Upload Arduino Sketch
```bash
# Open sketch.ino in Arduino IDE and upload to Nicla Vision
arduino-cli compile --fqbn arduino:mbed_nicla:nicla_vision sketch.ino
arduino-cli upload -p /dev/ttyACM0 --fqbn arduino:mbed_nicla:nicla_vision sketch.ino
```

### 4. Start Server
```bash
# Navigate to server directory
cd server/

# Install dependencies
pip install -r requirements.txt

# Start Flask server
python app.py
```

### 5. Configure WiFi
Update WiFi credentials in `sketch.ino`:
```cpp
const char* ssid = "YOUR_WIFI_SSID";
const char* password = "YOUR_WIFI_PASSWORD";
const char* serverURL = "http://YOUR_SERVER_IP:5000/classify";
```

---

## ğŸ“– Usage Guide

### Clinical Workflow

1. **Position Device**
   - Hold the MelaNoMore device over the patient's skin lesion
   - **Yellow LED** indicates positioning mode
   - ToF sensor ensures correct distance (3-5 cm)

2. **Capture Image**
   - Once positioned correctly, **Blue LED** activates
   - Image is automatically captured

3. **On-Device Classification**
   - Nicla Vision runs binary classification
   - **Green LED** = Non-suspicious (Done)
   - **Red LED** = Suspicious (Image uploaded to server)

4. **Server Analysis** (for suspicious cases only)
   - Image automatically transmitted via WiFi
   - Vision Transformer performs detailed 7-class classification
   - Results appear on web dashboard

5. **Review Results**
   - Dermatologist reviews detailed classification on PC dashboard
   - Prediction includes lesion type and confidence scores
   - Clinical decision made based on AI recommendation + medical expertise

---

## ğŸ’¡ LED Feedback System

| LED Color | Meaning |
|-----------|---------|
| ğŸŸ¡ Yellow | Positioning - adjust distance |
| ğŸ”µ Blue | Capturing image |
| ğŸŸ¢ Green | Non-suspicious lesion detected |
| ğŸ”´ Red | Suspicious lesion - uploading to server |

---

## ğŸ“ Project Structure

```
MelaNoMore/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ sketch.ino              # Arduino sketch for Nicla Vision
â”‚   â”œâ”€â”€ model.onnx              # Edge model (binary classification)
â”‚   â”œâ”€â”€ model_info.json         # Model metadata
â”‚   â””â”€â”€ server/
â”‚       â”œâ”€â”€ app.py              # Flask web server
â”‚       â”œâ”€â”€ vit_model.py        # Vision Transformer inference
â”‚       â””â”€â”€ requirements.txt    # Python dependencies
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ README.md               # Extended documentation
â”‚   â””â”€â”€ deployment-guide.md     # Deployment instructions
â”‚
â”œâ”€â”€ slides/
â”‚   â””â”€â”€ presentation.pdf        # Project presentation deck
â”‚
â””â”€â”€ README.md                   # This file
```

---

## âš¡ Technical Highlights

### Edge AI Optimization
- **Quantization**: ONNX model optimized for embedded inference
- **Resolution**: 96x96 input size balances accuracy and speed
- **Offline capability**: On-device inference works without internet

### Server-Side Intelligence
- **Focal Loss**: Addresses class imbalance in HAM10000 dataset
- **Vision Transformer**: State-of-the-art architecture for medical imaging
- **Scalability**: Server can handle multiple concurrent requests

### Sensor Fusion
- **ToF + Camera**: Ensures consistent image quality
- **WiFi + LED**: Provides seamless user experience

---

## ğŸ¯ Future Improvements

- Mobile app integration for patient record management
- Database integration for longitudinal lesion tracking
- Multi-language support for global deployment
- Real-time analytics dashboard for dermatology clinics
- HIPAA-compliant encryption for patient data

---

## ğŸ“š References

- **Dataset**: [HAM10000 - ISIC Archive](https://api.isic-archive.com/collections/212/)
- **Focoos AI**: [Model training and export platform](https://focoos.ai/)
- **Arduino Nicla Vision**: [Official Documentation](https://docs.arduino.cc/hardware/nicla-vision)
- **Z-Ant**: [Beer model timing](https://github.com/ZantFoundation/Z-Ant)
- **Vision Transformer**: [An Image is Worth 16x16 Words](https://arxiv.org/abs/2010.11929)

---

## ğŸ“œ License

This project was developed as part of a 24-hour hackathon challenge.

---

## ğŸ™ Acknowledgments

Special thanks to the organizers of the hackathon and the creators of the Focoos, Zant, and Arduino Nicla Vision platforms for making edge AI accessible to developers.

---

**MelaNoMore** - Empowering dermatologists with AI-driven decision support ğŸ©º

Built with â¤ï¸ by Arslan, Vittorio, and Alessandro
